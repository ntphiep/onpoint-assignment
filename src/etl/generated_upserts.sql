-- Generated upsert SQL

CREATE TABLE IF NOT EXISTS users (id INTEGER PRIMARY KEY, name TEXT, username TEXT, email TEXT, phone TEXT, website TEXT, address TEXT, company_name TEXT, company_catchphrase TEXT, company_bs TEXT, updated_at TIMESTAMPTZ DEFAULT now());

CREATE TABLE IF NOT EXISTS reddit_posts (id TEXT PRIMARY KEY, title TEXT, author TEXT, score INTEGER, num_comments INTEGER, created_utc TIMESTAMPTZ, selftext TEXT, subreddit TEXT, upvote_ratio NUMERIC, is_self BOOLEAN, updated_at TIMESTAMPTZ DEFAULT now());

-- Upserts for users

INSERT INTO users (id, name, username, email, phone, website, address, company_name, company_catchPhrase, company_bs, updated_at) VALUES (1, 'Leanne Graham', 'Bret', 'Sincere@april.biz', '1-770-736-8031 x56442', 'hildegard.org', 'Kulas Light, Apt. 556, Gwenborough, 92998-3874', 'Romaguera-Crona', 'Multi-layered client-server neural-net', 'harness real-time e-markets', now()) ON CONFLICT (id) DO UPDATE SET name=EXCLUDED.name, username=EXCLUDED.username, email=EXCLUDED.email, phone=EXCLUDED.phone, website=EXCLUDED.website, address=EXCLUDED.address, company_name=EXCLUDED.company_name, company_catchPhrase=EXCLUDED.company_catchPhrase, company_bs=EXCLUDED.company_bs, updated_at = now();
INSERT INTO users (id, name, username, email, phone, website, address, company_name, company_catchPhrase, company_bs, updated_at) VALUES (2, 'Ervin Howell', 'Antonette', 'Shanna@melissa.tv', '010-692-6593 x09125', 'anastasia.net', 'Victor Plains, Suite 879, Wisokyburgh, 90566-7771', 'Deckow-Crist', 'Proactive didactic contingency', 'synergize scalable supply-chains', now()) ON CONFLICT (id) DO UPDATE SET name=EXCLUDED.name, username=EXCLUDED.username, email=EXCLUDED.email, phone=EXCLUDED.phone, website=EXCLUDED.website, address=EXCLUDED.address, company_name=EXCLUDED.company_name, company_catchPhrase=EXCLUDED.company_catchPhrase, company_bs=EXCLUDED.company_bs, updated_at = now();
INSERT INTO users (id, name, username, email, phone, website, address, company_name, company_catchPhrase, company_bs, updated_at) VALUES (3, 'Clementine Bauch', 'Samantha', 'Nathan@yesenia.net', '1-463-123-4447', 'ramiro.info', 'Douglas Extension, Suite 847, McKenziehaven, 59590-4157', 'Romaguera-Jacobson', 'Face to face bifurcated interface', 'e-enable strategic applications', now()) ON CONFLICT (id) DO UPDATE SET name=EXCLUDED.name, username=EXCLUDED.username, email=EXCLUDED.email, phone=EXCLUDED.phone, website=EXCLUDED.website, address=EXCLUDED.address, company_name=EXCLUDED.company_name, company_catchPhrase=EXCLUDED.company_catchPhrase, company_bs=EXCLUDED.company_bs, updated_at = now();
INSERT INTO users (id, name, username, email, phone, website, address, company_name, company_catchPhrase, company_bs, updated_at) VALUES (4, 'Patricia Lebsack', 'Karianne', 'Julianne.OConner@kory.org', '493-170-9623 x156', 'kale.biz', 'Hoeger Mall, Apt. 692, South Elvis, 53919-4257', 'Robel-Corkery', 'Multi-tiered zero tolerance productivity', 'transition cutting-edge web services', now()) ON CONFLICT (id) DO UPDATE SET name=EXCLUDED.name, username=EXCLUDED.username, email=EXCLUDED.email, phone=EXCLUDED.phone, website=EXCLUDED.website, address=EXCLUDED.address, company_name=EXCLUDED.company_name, company_catchPhrase=EXCLUDED.company_catchPhrase, company_bs=EXCLUDED.company_bs, updated_at = now();
INSERT INTO users (id, name, username, email, phone, website, address, company_name, company_catchPhrase, company_bs, updated_at) VALUES (5, 'Chelsey Dietrich', 'Kamren', 'Lucio_Hettinger@annie.ca', '(254)954-1289', 'demarco.info', 'Skiles Walks, Suite 351, Roscoeview, 33263', 'Keebler LLC', 'User-centric fault-tolerant solution', 'revolutionize end-to-end systems', now()) ON CONFLICT (id) DO UPDATE SET name=EXCLUDED.name, username=EXCLUDED.username, email=EXCLUDED.email, phone=EXCLUDED.phone, website=EXCLUDED.website, address=EXCLUDED.address, company_name=EXCLUDED.company_name, company_catchPhrase=EXCLUDED.company_catchPhrase, company_bs=EXCLUDED.company_bs, updated_at = now();
INSERT INTO users (id, name, username, email, phone, website, address, company_name, company_catchPhrase, company_bs, updated_at) VALUES (6, 'Mrs. Dennis Schulist', 'Leopoldo_Corkery', 'Karley_Dach@jasper.info', '1-477-935-8478 x6430', 'ola.org', 'Norberto Crossing, Apt. 950, South Christy, 23505-1337', 'Considine-Lockman', 'Synchronised bottom-line interface', 'e-enable innovative applications', now()) ON CONFLICT (id) DO UPDATE SET name=EXCLUDED.name, username=EXCLUDED.username, email=EXCLUDED.email, phone=EXCLUDED.phone, website=EXCLUDED.website, address=EXCLUDED.address, company_name=EXCLUDED.company_name, company_catchPhrase=EXCLUDED.company_catchPhrase, company_bs=EXCLUDED.company_bs, updated_at = now();
INSERT INTO users (id, name, username, email, phone, website, address, company_name, company_catchPhrase, company_bs, updated_at) VALUES (7, 'Kurtis Weissnat', 'Elwyn.Skiles', 'Telly.Hoeger@billy.biz', '210.067.6132', 'elvis.io', 'Rex Trail, Suite 280, Howemouth, 58804-1099', 'Johns Group', 'Configurable multimedia task-force', 'generate enterprise e-tailers', now()) ON CONFLICT (id) DO UPDATE SET name=EXCLUDED.name, username=EXCLUDED.username, email=EXCLUDED.email, phone=EXCLUDED.phone, website=EXCLUDED.website, address=EXCLUDED.address, company_name=EXCLUDED.company_name, company_catchPhrase=EXCLUDED.company_catchPhrase, company_bs=EXCLUDED.company_bs, updated_at = now();
INSERT INTO users (id, name, username, email, phone, website, address, company_name, company_catchPhrase, company_bs, updated_at) VALUES (8, 'Nicholas Runolfsdottir V', 'Maxime_Nienow', 'Sherwood@rosamond.me', '586.493.6943 x140', 'jacynthe.com', 'Ellsworth Summit, Suite 729, Aliyaview, 45169', 'Abernathy Group', 'Implemented secondary concept', 'e-enable extensible e-tailers', now()) ON CONFLICT (id) DO UPDATE SET name=EXCLUDED.name, username=EXCLUDED.username, email=EXCLUDED.email, phone=EXCLUDED.phone, website=EXCLUDED.website, address=EXCLUDED.address, company_name=EXCLUDED.company_name, company_catchPhrase=EXCLUDED.company_catchPhrase, company_bs=EXCLUDED.company_bs, updated_at = now();
INSERT INTO users (id, name, username, email, phone, website, address, company_name, company_catchPhrase, company_bs, updated_at) VALUES (9, 'Glenna Reichert', 'Delphine', 'Chaim_McDermott@dana.io', '(775)976-6794 x41206', 'conrad.com', 'Dayna Park, Suite 449, Bartholomebury, 76495-3109', 'Yost and Sons', 'Switchable contextually-based project', 'aggregate real-time technologies', now()) ON CONFLICT (id) DO UPDATE SET name=EXCLUDED.name, username=EXCLUDED.username, email=EXCLUDED.email, phone=EXCLUDED.phone, website=EXCLUDED.website, address=EXCLUDED.address, company_name=EXCLUDED.company_name, company_catchPhrase=EXCLUDED.company_catchPhrase, company_bs=EXCLUDED.company_bs, updated_at = now();
INSERT INTO users (id, name, username, email, phone, website, address, company_name, company_catchPhrase, company_bs, updated_at) VALUES (10, 'Clementina DuBuque', 'Moriah.Stanton', 'Rey.Padberg@karina.biz', '024-648-3804', 'ambrose.net', 'Kattie Turnpike, Suite 198, Lebsackbury, 31428-2261', 'Hoeger LLC', 'Centralized empowering task-force', 'target end-to-end models', now()) ON CONFLICT (id) DO UPDATE SET name=EXCLUDED.name, username=EXCLUDED.username, email=EXCLUDED.email, phone=EXCLUDED.phone, website=EXCLUDED.website, address=EXCLUDED.address, company_name=EXCLUDED.company_name, company_catchPhrase=EXCLUDED.company_catchPhrase, company_bs=EXCLUDED.company_bs, updated_at = now();
-- Upserts for reddit_posts

INSERT INTO reddit_posts (id, title, author, score, num_comments, created_utc, selftext, subreddit, upvote_ratio, is_self, updated_at) VALUES ('1ny9jqm', 'Sunday Daily Thread: What''s everyone working on this week?', 'AutoModerator', 0, 3, '2025-10-05 00:00:33', '# Weekly Thread: What''s Everyone Working On This Week? üõ†Ô∏è  Hello /r/Python! It''s time to share what you''ve been working on! Whether it''s a work-in-progress, a completed masterpiece, or just a rough idea, let us know what you''re up to!  ## How it Works:  1. **Show &amp; Tell**: Share your current projects, completed works, or future ideas. 2. **Discuss**: Get feedback, find collaborators, or just chat about your project. 3. **Inspire**: Your project might inspire someone else, just as you might get inspired here.  ## Guidelines:  * Feel free to include as many details as you''d like. Code snippets, screenshots, and links are all welcome. * Whether it''s your job, your hobby, or your passion project, all Python-related work is welcome here.  ## Example Shares:  1. **Machine Learning Model**: Working on a ML model to predict stock prices. Just cracked a 90% accuracy rate! 2. **Web Scraping**: Built a script to scrape and analyze news articles. It''s helped me understand media bias better. 3. **Automation**: Automated my home lighting with Python and Raspberry Pi. My life has never been easier!  Let''s build and grow together! Share your journey and learn from others. Happy coding! üåü', 'Python', 0.5, TRUE, now()) ON CONFLICT (id) DO UPDATE SET title=EXCLUDED.title, author=EXCLUDED.author, score=EXCLUDED.score, num_comments=EXCLUDED.num_comments, created_utc=EXCLUDED.created_utc, selftext=EXCLUDED.selftext, subreddit=EXCLUDED.subreddit, upvote_ratio=EXCLUDED.upvote_ratio, is_self=EXCLUDED.is_self, updated_at = now();
INSERT INTO reddit_posts (id, title, author, score, num_comments, created_utc, selftext, subreddit, upvote_ratio, is_self, updated_at) VALUES ('1nxf9sn', 'Saturday Daily Thread: Resource Request and Sharing! Daily Thread', 'AutoModerator', 5, 0, '2025-10-04 00:00:33', '# Weekly Thread: Resource Request and Sharing üìö  Stumbled upon a useful Python resource? Or are you looking for a guide on a specific topic? Welcome to the Resource Request and Sharing thread!  ## How it Works:  1. **Request**: Can''t find a resource on a particular topic? Ask here! 2. **Share**: Found something useful? Share it with the community. 3. **Review**: Give or get opinions on Python resources you''ve used.  ## Guidelines:  * Please include the type of resource (e.g., book, video, article) and the topic. * Always be respectful when reviewing someone else''s shared resource.  ## Example Shares:  1. **Book**: ["Fluent Python"](https://www.amazon.com/Fluent-Python-Concise-Effective-Programming/dp/1491946008) \- Great for understanding Pythonic idioms. 2. **Video**: [Python Data Structures](https://www.youtube.com/watch?v=pkYVOmU3MgA) \- Excellent overview of Python''s built-in data structures. 3. **Article**: [Understanding Python Decorators](https://realpython.com/primer-on-python-decorators/) \- A deep dive into decorators.  ## Example Requests:  1. **Looking for**: Video tutorials on web scraping with Python. 2. **Need**: Book recommendations for Python machine learning.  Share the knowledge, enrich the community. Happy learning! üåü', 'Python', 1.0, TRUE, now()) ON CONFLICT (id) DO UPDATE SET title=EXCLUDED.title, author=EXCLUDED.author, score=EXCLUDED.score, num_comments=EXCLUDED.num_comments, created_utc=EXCLUDED.created_utc, selftext=EXCLUDED.selftext, subreddit=EXCLUDED.subreddit, upvote_ratio=EXCLUDED.upvote_ratio, is_self=EXCLUDED.is_self, updated_at = now();
INSERT INTO reddit_posts (id, title, author, score, num_comments, created_utc, selftext, subreddit, upvote_ratio, is_self, updated_at) VALUES ('1ny6svl', 'I made PyPIPlus.com ‚Äî a faster way to see all dependencies of any Python package', 'RoyalW1zard', 119, 72, '2025-10-04 21:58:32', 'Hey folks   I built a small tool called PyPIPlus.com that helps you quickly see all dependencies for any Python package on PyPI.  It started because I got tired of manually checking dependencies when installing packages on servers with limited or no internet access. We all know that pain trying to figure out what else you need to download by digging through package metadata or pip responses.   With PyPIPlus, you just type the package name and instantly get a clean list of all its dependencies (and their dependencies). No installation, no login, no ads ‚Äî just fast info.  Why it‚Äôs useful:  ‚Ä¢ Makes offline installs a lot easier (especially for isolated servers)  ‚Ä¢ Saves time  ‚Ä¢ Great for auditing or just understanding what a package actually pulls in  Would love to hear your thoughts ‚Äî bugs, ideas, or anything you think would make it better. It‚Äôs still early and I‚Äôm open to improving it.   https://pypiplus.com  UPDATE: thank you everyone for the positive comments and feedback, please feel free share any additional ideas we can make this a better tool. I‚Äôll be making sure of taking each comment and feature requests mentioned and try to make it available in the next push update üôè', 'Python', 0.92, TRUE, now()) ON CONFLICT (id) DO UPDATE SET title=EXCLUDED.title, author=EXCLUDED.author, score=EXCLUDED.score, num_comments=EXCLUDED.num_comments, created_utc=EXCLUDED.created_utc, selftext=EXCLUDED.selftext, subreddit=EXCLUDED.subreddit, upvote_ratio=EXCLUDED.upvote_ratio, is_self=EXCLUDED.is_self, updated_at = now();
INSERT INTO reddit_posts (id, title, author, score, num_comments, created_utc, selftext, subreddit, upvote_ratio, is_self, updated_at) VALUES ('1nxtuvm', 'Do you let linters modify code in your CI/CD pipeline?', 'mbsp5', 52, 118, '2025-10-04 13:21:44', 'For example, with black you can have it check but not modify. Do you think it‚Äôs safe enough to let it modify? I‚Äôve never heard of a horror story‚Ä¶ but maybe that‚Äôs because people don‚Äôt do it?', 'Python', 0.8, TRUE, now()) ON CONFLICT (id) DO UPDATE SET title=EXCLUDED.title, author=EXCLUDED.author, score=EXCLUDED.score, num_comments=EXCLUDED.num_comments, created_utc=EXCLUDED.created_utc, selftext=EXCLUDED.selftext, subreddit=EXCLUDED.subreddit, upvote_ratio=EXCLUDED.upvote_ratio, is_self=EXCLUDED.is_self, updated_at = now();
INSERT INTO reddit_posts (id, title, author, score, num_comments, created_utc, selftext, subreddit, upvote_ratio, is_self, updated_at) VALUES ('1nxy1nj', 'AnvPy ‚Äî Run &amp; Build Python Apps Natively on Android', 'Ajay7750', 21, 14, '2025-10-04 16:10:17', 'Check out our intro video: https://youtu.be/A04UM53TRZw?si=-90Mkja0ojRS8x5p  AnvPy is a next-generation framework designed for Python developers to build, deploy, and run Python applications directly on Android devices offline. With AnvPy, you can:  Write your project in pure Python  Instantly generate a native Android APK  Enjoy seamless execution on mobile without external dependencies  Leverage familiar Python libraries and toolchains   Whether you''re prototyping mobile apps, teaching Python, or shipping real-world tools ‚Äî AnvPy makes mobile development accessible and fast. Dive into the video to see a live demo and get started today!', 'Python', 0.75, TRUE, now()) ON CONFLICT (id) DO UPDATE SET title=EXCLUDED.title, author=EXCLUDED.author, score=EXCLUDED.score, num_comments=EXCLUDED.num_comments, created_utc=EXCLUDED.created_utc, selftext=EXCLUDED.selftext, subreddit=EXCLUDED.subreddit, upvote_ratio=EXCLUDED.upvote_ratio, is_self=EXCLUDED.is_self, updated_at = now();
INSERT INTO reddit_posts (id, title, author, score, num_comments, created_utc, selftext, subreddit, upvote_ratio, is_self, updated_at) VALUES ('1nys8rb', 'Python Violates PEP 8', 'AlSweigart', 0, 18, '2025-10-05 16:08:09', 'https://inventwithpython.com/blog/sweigarts-law-of-pep-8-complaints.html  Python itself doesn''t follow PEP 8, but what is the point of Python Enhancement Proposal document number 8, and how does it get used and misused? Why do we write code the way we do, and how meaningful are conversations about code style and readability anyway?  The spicy hot take in the article is Sweigart''s Law of PEP 8 Complaints is: *"Any time someone complains about source code violating PEP 8, they are always complaining that the source code uses camelCase instead of snake_case. The complaint is never about any other part of PEP 8."*  Also some discussion about style, code formatting tools, language design history, "bike shedding", and how to deal with low-quality contributions.', 'Python', 0.15, TRUE, now()) ON CONFLICT (id) DO UPDATE SET title=EXCLUDED.title, author=EXCLUDED.author, score=EXCLUDED.score, num_comments=EXCLUDED.num_comments, created_utc=EXCLUDED.created_utc, selftext=EXCLUDED.selftext, subreddit=EXCLUDED.subreddit, upvote_ratio=EXCLUDED.upvote_ratio, is_self=EXCLUDED.is_self, updated_at = now();
INSERT INTO reddit_posts (id, title, author, score, num_comments, created_utc, selftext, subreddit, upvote_ratio, is_self, updated_at) VALUES ('1nyrenf', 'For VScode users: What''s your opinion on Github Copilot''s autocompletion feature?', 'MaleficentBed1249', 0, 9, '2025-10-05 15:36:23', 'I use GitHub Copilot pretty much daily in my coding projects. My usual process is to start typing a line and see what Copilot suggests, then decide if it''s what I''m looking for or not. If it makes sense, I''ll accept it; if not, I''ll either modify it or write it myself.    Honestly, it''s made my coding way faster and more efficient. But I''ve got friends who think this isn''t "real coding" and that I''m just letting the AI do all the work. Some call it "vibe coding," which I guess is a thing now?    I don''t really agree though. You still need to understand the code and syntax to know whether Copilot''s suggestion is actually good or complete garbage. It''s more like having a really smart coding buddy who sometimes gives great suggestions and sometimes suggests weird stuff you have to ignore.    What''s everyone''s take on this? Are you team Copilot or do you think it''s not worthy of being called coding?', 'Python', 0.17, TRUE, now()) ON CONFLICT (id) DO UPDATE SET title=EXCLUDED.title, author=EXCLUDED.author, score=EXCLUDED.score, num_comments=EXCLUDED.num_comments, created_utc=EXCLUDED.created_utc, selftext=EXCLUDED.selftext, subreddit=EXCLUDED.subreddit, upvote_ratio=EXCLUDED.upvote_ratio, is_self=EXCLUDED.is_self, updated_at = now();
INSERT INTO reddit_posts (id, title, author, score, num_comments, created_utc, selftext, subreddit, upvote_ratio, is_self, updated_at) VALUES ('1nx0oxk', 'PEP 810 ‚Äì Explicit lazy imports', 'JanEric1', 438, 139, '2025-10-03 14:28:35', 'PEP: https://pep-previews--4622.org.readthedocs.build/pep-0810/  Discussion: https://discuss.python.org/t/pep-810-explicit-lazy-imports/104131  This PEP introduces lazy imports as an explicit language feature. Currently, a module is eagerly loaded at the point of the import statement. Lazy imports defer the loading and execution of a module until the first time the imported name is used.  By allowing developers to mark individual imports as lazy with explicit syntax, Python programs can reduce startup time, memory usage, and unnecessary work. This is particularly beneficial for command-line tools, test suites, and applications with large dependency graphs.  The proposal preserves full backwards compatibility: normal import statements remain unchanged, and lazy imports are enabled only where explicitly requested.', 'Python', 0.97, TRUE, now()) ON CONFLICT (id) DO UPDATE SET title=EXCLUDED.title, author=EXCLUDED.author, score=EXCLUDED.score, num_comments=EXCLUDED.num_comments, created_utc=EXCLUDED.created_utc, selftext=EXCLUDED.selftext, subreddit=EXCLUDED.subreddit, upvote_ratio=EXCLUDED.upvote_ratio, is_self=EXCLUDED.is_self, updated_at = now();
INSERT INTO reddit_posts (id, title, author, score, num_comments, created_utc, selftext, subreddit, upvote_ratio, is_self, updated_at) VALUES ('1nxtj9r', 'I created a framework for turning PyTorch training scripts into event driven systems.', 'EricHermosis', 3, 0, '2025-10-04 13:07:46', '**What My Project Does**  Hi! I''ve been training a lot of neural networks recently and want to share with you a tool I created.  While training pytorch models, I noticed that it is very hard to write reusable code for training models. There are packages that help track metrics, logs, and checkpoints, but they often create more problems than they solve. As a result, training pipelines become bloated with infrastructure code that obscures the actual business logic.  That‚Äôs why I created TorchSystem a package designed to help you build extensible training systems using domain-driven design principles, to replace ugly training scripts with clean, modular, and fully featured training services, with type annotations and modern python syntax.  **Repository**:[ https://github.com/entropy-flux/TorchSystem](https://github.com/entropy-flux/TorchSystem)  **Documentation**:[ https://entropy-flux.github.io/TorchSystem/](https://entropy-flux.github.io/TorchSystem/)  **Full working example**:[ https://github.com/entropy-flux/TorchSystem/tree/main/examples/mnist-mlp](https://github.com/entropy-flux/TorchSystem/tree/main/examples/mnist-mlp)  **Target Audience**  * ML engineers building **complex training pipelines** who need modularity. * Researchers experimenting with **custom training loops** without reinventing boilerplate. * Developers who want **DDD-inspired architecture** in their AI projects. * Anyone frustrated with hard-to-maintain "script soup" training code.  **Comparison**  * [pytorch-lightning](https://github.com/Lightning-AI/pytorch-lightning): There aren''t any framework doing this,[ pytorch-lightning](https://github.com/Lightning-AI/pytorch-lightning) come close by encapsulating all kind of infrastructure and the training loop inside a custom class, but it doesn''t provide a way to actually decouple the logic from the implementation details. You can use a LightningModule¬† instead of my Aggregate class, and use the whole the message system of the library to bind it with other tools you want. * [mlflow](https://github.com/mlflow/mlflow): Helps with model tracking and checkpoints, but again, you will end up with a lot of infrastructure logic inside your training loop, you can actually plug tracking libraries like this inside Consumer or a Subscriber and pass metrics as events or to topics as serializable messages. * [neptune.ai](https://neptune.ai/): Web infra for metric tracking, like[ mlflow](https://github.com/mlflow/mlflow) you can plug it like a consumer or a subscriber, the good thing is that thanks to dependency inversion you can plug many of these tracking libraries at the same time to the same publisher and send the metrics to all of them.  Hope you find it useful!', 'Python', 0.59, TRUE, now()) ON CONFLICT (id) DO UPDATE SET title=EXCLUDED.title, author=EXCLUDED.author, score=EXCLUDED.score, num_comments=EXCLUDED.num_comments, created_utc=EXCLUDED.created_utc, selftext=EXCLUDED.selftext, subreddit=EXCLUDED.subreddit, upvote_ratio=EXCLUDED.upvote_ratio, is_self=EXCLUDED.is_self, updated_at = now();
INSERT INTO reddit_posts (id, title, author, score, num_comments, created_utc, selftext, subreddit, upvote_ratio, is_self, updated_at) VALUES ('1nxt42j', 'pyro-mysql: a fast MySQL client library', 'Sad_Tap_9191', 1, 1, '2025-10-04 12:49:07', '* **Repo**    * [https://github.com/elbaro/pyro-mysql/](https://github.com/elbaro/pyro-mysql/) * **Bench**    * [https://github.com/elbaro/pyro-mysql/blob/main/report/chart.png?raw=true](https://github.com/elbaro/pyro-mysql/blob/main/report/chart.png?raw=true) * **What My Project Does**    * **pyro-mysql** is a fast MySQL client library. * **Target Audience** (e.g., Is it meant for production, just a toy project, etc)    * **pyro-mysql** benefits the reliability and speed of Rust.    * **pyro-mysql** delegates the protocol implementation to the existing Rust libraries, and the Python layer focuses on managing the lifetime of wrapped objects. This reduces the maintenance work of the Python package.    * It is meant for production, but needs more battle-tests. * **Comparison** (A brief comparison explaining how it differs from existing alternatives.)    * `pyro-mysql` does not implement PEP 249.       * There is no cursor.    * `mysqlclient`, `pymysql` \- they are synchronous.       * `pyro_mysql.sync` is faster.    * `aiomysql`, `asyncmy` \- they are asynchoronous.       * In my last workplace, our prod experience with them was not good.       * `FastAPI + aiomysql/asyncmy` setup had protocol errors (Packet Sequence Number wrong) in highly congested environment. We also often ran into critical bugs mixing the query result - the result of query1 was returned to query2.', 'Python', 0.56, TRUE, now()) ON CONFLICT (id) DO UPDATE SET title=EXCLUDED.title, author=EXCLUDED.author, score=EXCLUDED.score, num_comments=EXCLUDED.num_comments, created_utc=EXCLUDED.created_utc, selftext=EXCLUDED.selftext, subreddit=EXCLUDED.subreddit, upvote_ratio=EXCLUDED.upvote_ratio, is_self=EXCLUDED.is_self, updated_at = now();
INSERT INTO reddit_posts (id, title, author, score, num_comments, created_utc, selftext, subreddit, upvote_ratio, is_self, updated_at) VALUES ('1nx3hkg', '[Show &amp; Tell] PyClue/Cluedo-style deduction game in Python (pygame)', 'rozsit', 30, 0, '2025-10-03 16:13:36', '**What My Project Does**   I built a small Clue/Cluedo-style deduction game in **Python** using **pygame**. It‚Äôs a scene-based desktop game with clean, portable asset handling. You can run it from source or as a single **Windows .exe** (PyInstaller one-file). The repo is meant to be a practical reference for packaging pygame apps reliably.  **Source code (GitHub):**   [https://github.com/rozsit/112\_PyClue\_Game](https://github.com/rozsit/112_PyClue_Game)  *(Windows build is in the GitHub Release ‚Äî see ‚ÄúDownloads‚Äù below.)*  **Target Audience**  * Python devs interested in **pygame** architecture and **packaging to .exe**. * Learners who want a small, readable codebase (scenes, UI, audio, animations). * Casual players who just want to double-click an `.exe` and try a Clue-like game.  **Comparison**   Compared with other ‚Äúpygame Clue clones‚Äù or small hobby games, this repo focuses on **robust distribution** and **developer ergonomics**:  * Works the same in **dev** and **frozen** modes (PyInstaller). * Global hooks route string paths for `pygame.image.load`, `pygame.mixer.Sound`, and `pygame.mixer.music.load` ‚Üí fewer path bugs after packaging. * **Audio init** on Windows is hardened (`ensure_audio()` tries multiple drivers/buffer sizes). * **Animated GIF** support via **Pillow** (e.g., winner screen fireworks ‚Üí frames + per-frame duration). * Comes with a one-command **build script** (PowerShell) and a **SHA-256** file for integrity checks.  **How Python Is Used**  * **pygame** for windowing, scenes, input, and rendering. * **Pillow** to decode animated GIFs into (surface, duration) frames. * **PyInstaller** (one-file) to ship a single `.exe`.  **Minimal snippets (the core ideas):**      # resource_path: dev + PyInstaller (_MEIPASS) friendly     from pathlib import Path     import sys     def resource_path(*parts):         if hasattr(sys, "_MEIPASS"):             base = Path(sys._MEIPASS)         else:             here = Path(__file__).resolve()             base = next((p for p in [here] + list(here.parents) if (p / "assets").exists()), here)         return str((base / Path(*parts)).resolve())           # global hooks so string paths work after packaging, too     import pygame     _orig_img = pygame.image.load     def _img_wrapped(path, *a, **kw):         from utils import resource_path         if isinstance(path, str): path = resource_path(path)         return _orig_img(path, *a, **kw)     pygame.image.load = _img_wrapped          # similar tiny wrappers exist for pygame.mixer.Sound and pygame.mixer.music.load       **Run from Source**      git clone https://github.com/rozsit/112_PyClue_Game     cd 112_PyClue_Game     python -m venv .venv     .\.venv\Scripts\activate           # Windows     pip install -r requirements.txt     python main.py       **Downloads (Windows .exe)**   Grab the one-file build from the Release page:   [https://github.com/rozsit/112\_PyClue\_Game/releases/tag/v1.0.0](https://github.com/rozsit/112_PyClue_Game/releases/tag/v1.0.0)  **(Optional) Verify SHA-256 on Windows**      Get-FileHash .\PyClue.exe -Algorithm SHA256     # or     certutil -hashfile .\PyClue.exe SHA256       The output should match the `PyClue.exe.sha256` provided in the release.  **Roadmap / PRs Welcome**  * New boards, items, rule variants * Simple AI opponents * Local/online multiplayer * Localization (EN/HU) * Save/load &amp; stats  I‚Äôd love feedback on packaging tricks (PyInstaller + pygame), audio reliability on different Windows setups, and ergonomics of the scene/asset layout.', 'Python', 0.98, TRUE, now()) ON CONFLICT (id) DO UPDATE SET title=EXCLUDED.title, author=EXCLUDED.author, score=EXCLUDED.score, num_comments=EXCLUDED.num_comments, created_utc=EXCLUDED.created_utc, selftext=EXCLUDED.selftext, subreddit=EXCLUDED.subreddit, upvote_ratio=EXCLUDED.upvote_ratio, is_self=EXCLUDED.is_self, updated_at = now();
INSERT INTO reddit_posts (id, title, author, score, num_comments, created_utc, selftext, subreddit, upvote_ratio, is_self, updated_at) VALUES ('1ny2zk8', 'Is zfill() useless in Python?', 'Timely-Cat-6587', 0, 14, '2025-10-04 19:23:55', 'I‚Äôm trying to learn all of Python‚Äôs built-in functions before starting OOP, so I‚Äôm curious how this function could be used in real projects.', 'Python', 0.27, TRUE, now()) ON CONFLICT (id) DO UPDATE SET title=EXCLUDED.title, author=EXCLUDED.author, score=EXCLUDED.score, num_comments=EXCLUDED.num_comments, created_utc=EXCLUDED.created_utc, selftext=EXCLUDED.selftext, subreddit=EXCLUDED.subreddit, upvote_ratio=EXCLUDED.upvote_ratio, is_self=EXCLUDED.is_self, updated_at = now();
INSERT INTO reddit_posts (id, title, author, score, num_comments, created_utc, selftext, subreddit, upvote_ratio, is_self, updated_at) VALUES ('1nx12sv', 'How to Level Up Your Python Logs with Structlog', 'finallyanonymous', 19, 11, '2025-10-03 14:43:30', 'For modern applications, structured and context-aware logging is essential for observability. [Structlog](https://www.structlog.org/) is one of the better tools in the Python ecosystem for achieving this with a more intuitive model than the standard logging''s system of handlers, formatters, and filters.  [I wrote a guide](https://www.dash0.com/guides/python-logging-with-structlog) that provides a step-by-step walkthrough for implementing clean, production-ready logging with Structlog.  Keen to hear your thoughts, and if you think it''s worth switching to from the `logging` module.', 'Python', 0.78, TRUE, now()) ON CONFLICT (id) DO UPDATE SET title=EXCLUDED.title, author=EXCLUDED.author, score=EXCLUDED.score, num_comments=EXCLUDED.num_comments, created_utc=EXCLUDED.created_utc, selftext=EXCLUDED.selftext, subreddit=EXCLUDED.subreddit, upvote_ratio=EXCLUDED.upvote_ratio, is_self=EXCLUDED.is_self, updated_at = now();
INSERT INTO reddit_posts (id, title, author, score, num_comments, created_utc, selftext, subreddit, upvote_ratio, is_self, updated_at) VALUES ('1nwv8re', 'pyya - Simple tool that converts YAML/TOML configuration files to Python objects', 'wit4er', 22, 6, '2025-10-03 10:19:40', 'New version 0.1.11 is ready, now *pyya* can convert and validate configuaration from TOML files. In the previous version, I also added a CLI tool to generate stub files from your YAML/TOML configuaration fil, so that tools like mypy can validate type hints and varoius LSPs can autocomplete dynamic attribute-style dictionary. Check README for more info. Contributions/suggestions are welcome as always.  Check GitHub Page: [https://github.com/shadowy-pycoder/pyya](https://github.com/shadowy-pycoder/pyya)   Check PyPi Page: [https://pypi.org/project/pyya/](https://pypi.org/project/pyya/)', 'Python', 0.89, TRUE, now()) ON CONFLICT (id) DO UPDATE SET title=EXCLUDED.title, author=EXCLUDED.author, score=EXCLUDED.score, num_comments=EXCLUDED.num_comments, created_utc=EXCLUDED.created_utc, selftext=EXCLUDED.selftext, subreddit=EXCLUDED.subreddit, upvote_ratio=EXCLUDED.upvote_ratio, is_self=EXCLUDED.is_self, updated_at = now();
INSERT INTO reddit_posts (id, title, author, score, num_comments, created_utc, selftext, subreddit, upvote_ratio, is_self, updated_at) VALUES ('1nwxqad', 'Simulate Apache Spark Workloads Without a Cluster using FauxSpark', 'No_Direction_5276', 6, 1, '2025-10-03 12:27:12', '**What My Project Does**  [FauxSpark](https://github.com/fhalde/fauxspark) is a discrete event simulation of Apache Spark using SimPy. It lets you experiment with Spark workloads and cluster configurations without spinning up a real cluster ‚Äì perfect for testing failures, scheduling, or capacity planning to observe the impact it has on your workload.  The first version includes:  * DAG scheduling with stages, tasks, and dependencies * Automatic retries on executor or shuffle-fetch failures * Single-job execution with configurable cluster parameters * Simple CLI to tweak cluster size, simulate failures, and scaling up executors  **Target Audience**  * **Data &amp; Infrastructure engineers** running Apache Spark who want to experiment with cluster configurations * Anyone curious about **Spark internals**  I''d love feedback from anyone with experience in discrete event simulation, especially on the planned features, as well as from anyone who found this useful. I have created some example DAGs for you to try it out!  GH repo [https://github.com/fhalde/fauxspark](https://github.com/fhalde/fauxspark)', 'Python', 0.81, TRUE, now()) ON CONFLICT (id) DO UPDATE SET title=EXCLUDED.title, author=EXCLUDED.author, score=EXCLUDED.score, num_comments=EXCLUDED.num_comments, created_utc=EXCLUDED.created_utc, selftext=EXCLUDED.selftext, subreddit=EXCLUDED.subreddit, upvote_ratio=EXCLUDED.upvote_ratio, is_self=EXCLUDED.is_self, updated_at = now();
INSERT INTO reddit_posts (id, title, author, score, num_comments, created_utc, selftext, subreddit, upvote_ratio, is_self, updated_at) VALUES ('1nwnr98', 'PyThermite - Rust backed object indexer', 'Interesting-Frame190', 41, 16, '2025-10-03 02:51:04', 'Attention ‚ö†Ô∏è : NOT another AI wrapper  Beta released today - open to feedback - especially bugs  https://github.com/tylerrobbins5678/PyThermite  https://pypi.org/project/pythermite/  -**what My Project Does**  PyThermite is a rust backed python object indexer that supports nested objects and queries with real-time data. In plain terms, this means that complex data relations can be conveyed in objects, maintained state, and queried easily. For example, if I have a list of 100k cars in a city and want to get a list of cars moving between 20 and 40 mph and the owner of the car is named "Jim" that was born after 2005, that can be a single built query with sub 1 ms response. Keep in mind that the cars speed is constantly changing, updating the data structures as it goes.  In testing, its significantly (20- 50x) faster than pandas dataframe filtering on a data size of 100k. Query time complexity is roughly O(q + r) where q is the amount of query operations (and, or, in, eq, gt, nesting, etc) and r is the result size.   The cost to index is defined paid and building the structure takes around 6-7x longer than a dataframe consuming a list, but definitely worth it if the data is queried more than 3-4 times  Performance has been and is still a constant battle with the hashmap and b-tree inserts consuming most of the process time.   -**Target Audience**  Currently this is not production ready as it is not tested thoroughly. Once proven, it will be supported and continue driving towards ETL and simulation within OOP driven code. At this current state it should only be used for analytics and analysis   -**Conparison**  This competes with traditional dataframes like arrow, pandas, and polars, except it is the only one that handles native objects internally as well as indexes attributes for highly performant lookup. There''s a few small alternatives out there, but nothing written with this much focus on performance.', 'Python', 0.87, TRUE, now()) ON CONFLICT (id) DO UPDATE SET title=EXCLUDED.title, author=EXCLUDED.author, score=EXCLUDED.score, num_comments=EXCLUDED.num_comments, created_utc=EXCLUDED.created_utc, selftext=EXCLUDED.selftext, subreddit=EXCLUDED.subreddit, upvote_ratio=EXCLUDED.upvote_ratio, is_self=EXCLUDED.is_self, updated_at = now();
INSERT INTO reddit_posts (id, title, author, score, num_comments, created_utc, selftext, subreddit, upvote_ratio, is_self, updated_at) VALUES ('1nwy2zb', 'OCR-StringDist - Learn and Fix OCR Errors', 'NiklasvonM', 6, 0, '2025-10-03 12:43:16', '# What My Project Does  I built this library to fix errors in product codes read from images.  For example, "O" and "0" look very similar and are therefore often mixed up by OCR models. However, most string distance implementations do not consider character similarity.  Therefore, I implemented a weighted Levenshtein string distance with configurable costs on a character- or token-level.  These weights can either be configured manually or they can be learned from a dataset of (read, true) labels using a probabilistic learning algorithm.  # Basic Usage      from ocr_stringdist import WeightedLevenshtein          training_data = [         ("128", "123"), # 3 misread as 8         ("567", "567"),     ]     # Holds learned substitution, insertion and deletion weights     wl = WeightedLevenshtein.learn_from(training_data)          ocr_output = "Product Code 148"     candidates = [         "Product Code 143",         "Product Code 848",     ]     distances: list[float] = wl.batch_distance(ocr_output, candidates)  # Target Audience  Professionals who work on data extraction from images.  # Comparison  There are multiple string distance libraries, such as [rapidfuzz](https://github.com/rapidfuzz/RapidFuzz), [jellyfish](https://github.com/jamesturk/jellyfish), [textdistance](https://github.com/life4/textdistance) and [weighted-levenshtein](https://github.com/infoscout/weighted-levenshtein), with most of them being a bit faster and having more diverse string distances.  However, there are very few good implementations that support character- or token-level weights and I am not aware of any that support learning weights from training data.  # Links  [Repository](https://github.com/NiklasvonM/ocr-stringdist) [pypi](https://pypi.org/project/ocr-stringdist/) [Documentation](https://niklasvonm.github.io/ocr-stringdist/)  I''m grateful for any feedback and hope that my project might be useful to someone.', 'Python', 1.0, TRUE, now()) ON CONFLICT (id) DO UPDATE SET title=EXCLUDED.title, author=EXCLUDED.author, score=EXCLUDED.score, num_comments=EXCLUDED.num_comments, created_utc=EXCLUDED.created_utc, selftext=EXCLUDED.selftext, subreddit=EXCLUDED.subreddit, upvote_ratio=EXCLUDED.upvote_ratio, is_self=EXCLUDED.is_self, updated_at = now();
INSERT INTO reddit_posts (id, title, author, score, num_comments, created_utc, selftext, subreddit, upvote_ratio, is_self, updated_at) VALUES ('1nwi0jd', 'PyCharm Pro Gift Code | 1-Year FREE', 'DrDeems', 70, 29, '2025-10-02 22:23:40', '**Hail**, fellow Python lovers!  I randomly found a great deal today. I was going to subscribe to PyCharm Pro monthly for personal use (they have a few features that integrate with GCloud I would like to leverage). On the checkout page, I saw a "Have a gift code?" prompt. I googled "PyCharm Pro coupon code" or something like that.  One of the first few websites in the results had a handful of coupons listed to use. First try, boom 25% off, not bad. Second try, boom 25% off again, not bad. Third try, boom... wait... 100 percent off, what in the hell?!?! I selected PayPal as my payment option. Since the total was $0.00, it did not ask me for my PayPal email. It showed the purchase success page with a receipt for $0.00. Paying nothing for a product that normally costs $209.99/year felt pretty good!  The coupon code you enter on the checkout page is:  **Chand\_Sheikh**  You can only redeem the Gift Code once per account! You can choose one of the eleven IDEs offered by IntelliJ (PyCharm, PHPStorm, RustRover, RubyMine, ReSharper, etc, etc.). So choose wisely!  The only thing I ask in return for this information is that you take a moment to try to make someone else''s day a bit better üíñ It can be anyone. Spread love!  **TLDR**: You can get a free year of one of the eleven premium IDEs IntelliJ sells by using the gift code "*Chand\_Sheikh*". Do something to make another person''s day a bit better.  *Parts of this post were* ***NOT*** *written with ChatGPT or Ai. I prefer to add my own touch.*', 'Python', 0.74, TRUE, now()) ON CONFLICT (id) DO UPDATE SET title=EXCLUDED.title, author=EXCLUDED.author, score=EXCLUDED.score, num_comments=EXCLUDED.num_comments, created_utc=EXCLUDED.created_utc, selftext=EXCLUDED.selftext, subreddit=EXCLUDED.subreddit, upvote_ratio=EXCLUDED.upvote_ratio, is_self=EXCLUDED.is_self, updated_at = now();
INSERT INTO reddit_posts (id, title, author, score, num_comments, created_utc, selftext, subreddit, upvote_ratio, is_self, updated_at) VALUES ('1nwhdmt', 'Snakebar ‚Äî a tqdm-style progress bar that snakes across your terminal', 'Library-Extra', 72, 21, '2025-10-02 21:58:11', '## What My Project Does   Snakebar is a `tqdm`-like progress bar for Python. Instead of a plain horizontal bar, it draws a one-character snake that fills your terminal via a random space-filling curve.     It still reports percentage, iterations done, ETA, and rate (it/s), but makes waiting more fun.      ## Target Audience   Anyone who runs long scripts, pipelines, or training loops ‚Äî data scientists, ML engineers, researchers, developers with heavy ETL or simulations.     It‚Äôs meant as a lightweight library you can drop in as a direct replacement for `tqdm`. It‚Äôs production-ready but also works fine as a fun toy project in personal scripts.      ## Comparison   Compared to `tqdm`:   - Same semantics (`snake_bar` works like `tqdm`).   - Still shows % complete, ETA, and rate.   - Instead of a static bar, progress is visualized as a snake filling the screen.   - Fits automatically to your terminal size.      ## Installation   ```bash   pip install snakebar   ```  ## Links   - PyPI: [https://pypi.org/project/snakebar/](https://pypi.org/project/snakebar/)   - GitHub: [https://github.com/majoburo/snakebar](https://github.com/majoburo/snakebar)   - License: MIT', 'Python', 0.95, TRUE, now()) ON CONFLICT (id) DO UPDATE SET title=EXCLUDED.title, author=EXCLUDED.author, score=EXCLUDED.score, num_comments=EXCLUDED.num_comments, created_utc=EXCLUDED.created_utc, selftext=EXCLUDED.selftext, subreddit=EXCLUDED.subreddit, upvote_ratio=EXCLUDED.upvote_ratio, is_self=EXCLUDED.is_self, updated_at = now();
INSERT INTO reddit_posts (id, title, author, score, num_comments, created_utc, selftext, subreddit, upvote_ratio, is_self, updated_at) VALUES ('1nx8bzo', 'My journey from PyCon Accra 2024 to preparing for PyCon Africa 2025 in South Africa', 'Kof7029', 0, 0, '2025-10-03 19:14:15', 'I‚Äôm [DJAKPA Koffi](https://www.linkedin.com/in/djakpa-koffi), a tech enthusiast from Togo.  In October 2024, I had the incredible opportunity to attend **PyCon Africa in Accra, Ghana**. I learned a lot, met inspiring developers from across Africa, and returned home motivated to share my knowledge.  At my return, with friends, we organized an **Extender in Lom√©**, which brought together nearly 200 registrants and over 150 attendees. It was amazing to see the engagement and interest from participants, confirming that our efforts were having a real impact.  Now, I am preparing to attend **PyCon Africa 2025 in South Africa** to continue learning and bring back even more knowledge to share with young learners.   A few days before the event, reality catches up with me, and to change that reality, I need your support ( [https://gofund.me/2df7717be](https://gofund.me/2df7717be) ), whatever form it may take. Thank you for your time and attention.', 'Python', 0.5, TRUE, now()) ON CONFLICT (id) DO UPDATE SET title=EXCLUDED.title, author=EXCLUDED.author, score=EXCLUDED.score, num_comments=EXCLUDED.num_comments, created_utc=EXCLUDED.created_utc, selftext=EXCLUDED.selftext, subreddit=EXCLUDED.subreddit, upvote_ratio=EXCLUDED.upvote_ratio, is_self=EXCLUDED.is_self, updated_at = now();
INSERT INTO reddit_posts (id, title, author, score, num_comments, created_utc, selftext, subreddit, upvote_ratio, is_self, updated_at) VALUES ('1nwxo9z', 'Real-time Air Quality Monitoring with Python, BLE, and Ubidots', 'bleuio', 4, 0, '2025-10-03 12:24:40', 'Built a real-time air quality monitoring system in Python using a BleuIO dongle and visualize in Ubidots. It listens to BLE packets from a HibouAir sensor, decodes CO2/temperature/humidity, and streams the data to a live dashboard.   [https://www.bleuio.com/blog/connecting-bleuio-to-ubidots-a-practical-industrial-iot-air-quality-solution/](https://www.bleuio.com/blog/connecting-bleuio-to-ubidots-a-practical-industrial-iot-air-quality-solution/)', 'Python', 0.83, TRUE, now()) ON CONFLICT (id) DO UPDATE SET title=EXCLUDED.title, author=EXCLUDED.author, score=EXCLUDED.score, num_comments=EXCLUDED.num_comments, created_utc=EXCLUDED.created_utc, selftext=EXCLUDED.selftext, subreddit=EXCLUDED.subreddit, upvote_ratio=EXCLUDED.upvote_ratio, is_self=EXCLUDED.is_self, updated_at = now();
INSERT INTO reddit_posts (id, title, author, score, num_comments, created_utc, selftext, subreddit, upvote_ratio, is_self, updated_at) VALUES ('1nwk7ps', 'Friday Daily Thread: r/Python Meta and Free-Talk Fridays', 'AutoModerator', 3, 0, '2025-10-03 00:00:51', '# Weekly Thread: Meta Discussions and Free Talk Friday üéôÔ∏è  Welcome to Free Talk Friday on /r/Python! This is the place to discuss the r/Python community (meta discussions), Python news, projects, or anything else Python-related!  ## How it Works:  1. **Open Mic**: Share your thoughts, questions, or anything you''d like related to Python or the community. 2. **Community Pulse**: Discuss what you feel is working well or what could be improved in the /r/python community. 3. **News &amp; Updates**: Keep up-to-date with the latest in Python and share any news you find interesting.  ## Guidelines:  * All topics should be related to Python or the /r/python community. * Be respectful and follow Reddit''s [Code of Conduct](https://www.redditinc.com/policies/content-policy).  ## Example Topics:  1. **New Python Release**: What do you think about the new features in Python 3.11? 2. **Community Events**: Any Python meetups or webinars coming up? 3. **Learning Resources**: Found a great Python tutorial? Share it here! 4. **Job Market**: How has Python impacted your career? 5. **Hot Takes**: Got a controversial Python opinion? Let''s hear it! 6. **Community Ideas**: Something you''d like to see us do? tell us.  Let''s keep the conversation going. Happy discussing! üåü', 'Python', 0.81, TRUE, now()) ON CONFLICT (id) DO UPDATE SET title=EXCLUDED.title, author=EXCLUDED.author, score=EXCLUDED.score, num_comments=EXCLUDED.num_comments, created_utc=EXCLUDED.created_utc, selftext=EXCLUDED.selftext, subreddit=EXCLUDED.subreddit, upvote_ratio=EXCLUDED.upvote_ratio, is_self=EXCLUDED.is_self, updated_at = now();
INSERT INTO reddit_posts (id, title, author, score, num_comments, created_utc, selftext, subreddit, upvote_ratio, is_self, updated_at) VALUES ('1nvvsub', 'OneCode ‚Äî Python library to turn scripts into deployable apps', 'goochop', 44, 4, '2025-10-02 05:58:48', '# What My Project Does  **OneCode** is an open-source Python library that lets you convert your scripts to apps with minimal boilerplate. Using simple decorators/parameters, you define inputs/outputs, and OneCode automatically generates a UI for you.  Github link is here: [https://github.com/deeplime-io/onecode](https://github.com/deeplime-io/onecode)  On **OneCode Cloud**, those same apps can be deployed instantly, with authentication, scaling, and access controls handled for you.  The cloud platform is here: [https://www.onecode.rocks/](https://www.onecode.rocks/) (free tier includes 3 apps, 1Gb of storage and up to 5 hours of compute).  OneCode allows you to run the same code locally or on the cloud platform (one code ;)). You can connect your github account and automatically sync code to generate the app.  # Target Audience  * **Python developers** who want to share tools without building a web frontend * **Data scientists / researchers** who need to wrap analysis scripts with a simple interface * **Teams** that want internal utilities, but don‚Äôt want to manage deployment infrastructure * Suitable for **production apps** (access-controlled, secure), but lightweight enough for **prototyping and demos**.  # Comparison  * Unlike **Streamlit/Gradio**, OneCode doesn‚Äôt focus on dashboards, instead it auto-generates minimal UIs from your function signatures. OneCode cloud is also usable with long running compute, big machines are available, and compute is scalable with the number of users. * Unlike **Flask/FastAPI**, you don‚Äôt need to wire up endpoints, HTML, or auth, it‚Äôs all handled automatically. * The **cloud offering** provides secure runtime, scaling, and sharing out of the box, whereas most libraries stop at local execution.  Code examples:  `INPUTS`      `# instead of: df = pd.read_csv(''test.csv'')`          `df = csv_reader(''your df'', ''test.csv'')`                    `# instead of: for i in range(5):`          `for i in range(slider(''N'', 5, min=0, max=10)):  # inlined`         # do stuff      `# instead of: choice = ''cat''`          `choice = dropdown(''your choice'', ''cat'', options=[''dog'', ''cat'', ''fish''])`           `#not inlined`          `Logger.info(f''Your choice is {choice}'')`  `OUTPUTS`      `# instead of: plt.savefig(''stuff.png'')`          `plt.savefig(file_output(''stuff'', ''stuff.png''))  # inlined`                    `# instead of: filepath = ''test.txt''`          `filepath = file_output(''test'', ''test.txt'')  # not inlined`          `with open(filepath, ''w'') as f:`           # do stuff    Happy to answer questions or provide more examples! We have a few example apps on the cloud already which are available to everyone. You can find a webinar on the library and cloud here:  [https://www.youtube.com/watch?v=BPj\_cbRUwLk](https://www.youtube.com/watch?v=BPj_cbRUwLk)  We are looking for any feedback at this point! cheers', 'Python', 0.87, TRUE, now()) ON CONFLICT (id) DO UPDATE SET title=EXCLUDED.title, author=EXCLUDED.author, score=EXCLUDED.score, num_comments=EXCLUDED.num_comments, created_utc=EXCLUDED.created_utc, selftext=EXCLUDED.selftext, subreddit=EXCLUDED.subreddit, upvote_ratio=EXCLUDED.upvote_ratio, is_self=EXCLUDED.is_self, updated_at = now();
INSERT INTO reddit_posts (id, title, author, score, num_comments, created_utc, selftext, subreddit, upvote_ratio, is_self, updated_at) VALUES ('1nvnyjr', 'Open Source Google Maps Street View Panorama Scraper.', 'yousephx', 26, 4, '2025-10-01 23:25:10', '   **What My Project Does**      \- With [gsvp-dl](https://github.com/yousephzidan/gsvp-dl), an open source solution written in Python, you are able to download millions of panorama images off Google Maps Street View.  **Comparison**  \- Unlike other existing solutions (which fail to address major edge cases), [gsvp-dl](https://github.com/yousephzidan/gsvp-dl) downloads panoramas in their correct form and size with unmatched accuracy. Using Python Asyncio and Aiohttp, it can handle bulk downloads, scaling to millions of panoramas per day.  \- Other solutions don‚Äôt match up because they ignore edge cases, especially pre-2016 images with different resolutions. They used fixed width and height that only worked for post-2016 panoramas, which caused black spaces in older ones.  **Target Audience**¬†  "For educational purposes only" ***- just in case Google is watching.***   It was a fun project to work on, as there was no documentation whatsoever, whether by Google or other existing solutions. So, I documented the key points that explain why a panorama image looks the way it does based on the given inputs (mainly zoom levels).  The way I was able to reverse engineer Google Maps Street View API was by sitting all day for a week, doing nothing but observing the results of the endpoint, testing inputs, assembling panoramas, observing outputs, and repeating. With no documentation, no lead, and no reference, it was all trial and error.  I believe I have covered most edge cases, though I still doubt I may have missed some. Despite testing hundreds of panoramas at different inputs, I‚Äôm sure there could be a case I didn‚Äôt encounter. So feel free to fork the repo and make a pull request if you come across one, or find a bug/unexpected behavior.  Thanks for checking it out!', 'Python', 0.91, TRUE, now()) ON CONFLICT (id) DO UPDATE SET title=EXCLUDED.title, author=EXCLUDED.author, score=EXCLUDED.score, num_comments=EXCLUDED.num_comments, created_utc=EXCLUDED.created_utc, selftext=EXCLUDED.selftext, subreddit=EXCLUDED.subreddit, upvote_ratio=EXCLUDED.upvote_ratio, is_self=EXCLUDED.is_self, updated_at = now();
INSERT INTO reddit_posts (id, title, author, score, num_comments, created_utc, selftext, subreddit, upvote_ratio, is_self, updated_at) VALUES ('1nweuv0', 'BuildLog: a simple tool to track and version your Python builds', 'Frosty-Jackfruit-977', 0, 0, '2025-10-02 20:22:30', 'Hey r/Python! üëã  I‚Äôd like to share BuildLog, a Python CLI tool for tracking and versioning build outputs. It‚Äôs designed for standalone executables built with PyInstaller, Nuitka, or any other build command.  # What my project does  Basically, when you run a build, BuildLog captures all the new files/folders built at the current state of your repository, recording SHA256 hashes of executables, and logging Git metadata (commit, branch, tags, commit message). Everything goes into a .buildlog folder so you can always trace which build came from which commit.  One cool thing: it doesn‚Äôt care which build tool you use. It basically just wraps whatever command you pass and tracks what it produces. So even if you use something other than PyInstaller or Nuitka, it should still work.  # Target Audience  - Python developers building standalone executables.  - Teams that need reproducible builds and clear history.  - Anyone needing traceable builds.  # Comparison  I did not find similar tools to match my use cases, so I thought to build my own and I‚Äôm now happy to share it with you. Any feedback is welcome.   Check it out here to find more:  [BuildLog](https://github.com/adghin/buildlog) ‚Äì if you like it, feel free to give it a ‚≠ê!', 'Python', 0.33, TRUE, now()) ON CONFLICT (id) DO UPDATE SET title=EXCLUDED.title, author=EXCLUDED.author, score=EXCLUDED.score, num_comments=EXCLUDED.num_comments, created_utc=EXCLUDED.created_utc, selftext=EXCLUDED.selftext, subreddit=EXCLUDED.subreddit, upvote_ratio=EXCLUDED.upvote_ratio, is_self=EXCLUDED.is_self, updated_at = now();